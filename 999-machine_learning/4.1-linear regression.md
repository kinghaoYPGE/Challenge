### 1. Simple Linear Regression

#### Step 1: Pre-Process the data

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

dataset = pd.read_csv('studentscores.csv')
X = dataset.iloc[ : ,   : 1 ].values
Y = dataset.iloc[ : , 1 ].values

from sklearn.cross_validation import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0) 
```

#### Step 2: Fitting model to the training set

```
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor = regressor.fit(X_train, Y_train)
```

#### Step 3: Predicting the result

We will predict the observations from test set. 

We will save the output in a vector Y_pred

```
Y_pred = regressor.predict(X_test)
```

#### Step 4: Visualization

Make Scatter Plots of Training set results and Test set results

to see how close our model predicted the values

```
# Visualising the Training results
plt.scatter(X_train , Y_train, color = 'red')
plt.plot(X_train , regressor.predict(X_train), color ='blue')

# Visualizing the test results
plt.scatter(X_test , Y_test, color = 'red')
plt.plot(X_test , regressor.predict(X_test), color ='blue')
```



### 2. Multiple Linear Regression

We can find out which factor has the highest impact on the predicted output and how different variables relate to each other

#### Step 1: Data Preprocessing

```
#Importing the libraries
import pandas as pd
import numpy as np

#Importing the dataSet
dataset = pd.read_csv('50_Startups.csv')
X = dataset.iloc[ : , :-1].values
Y = dataset.iloc[ : ,  4 ].values

#Encoding Categorical data
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder = LabelEncoder()
X[: , 3] = labelencoder.fit_transform(X[ : , 3])
onehotencoder = OneHotEncoder(categorical_features = [3])
X = onehotencoder.fit_transform(X).toarray()

#Avoiding Dummy Variable Trap
X = X[:, 1:]

#Splitting the dataset into the Training set and Test set
from sklearn.cross_validation import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)
```

#### Step 2: Fitting Multiple Linear Regression to the Training set

```
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, Y_train)
```

#### Step 3: Predicting the Test set results

```
y_pred = regressor.predict(X_test)
```

### 3. 实战

#### 实战 1-对股票数据进行分析预测

- [ ] https://www.shiyanlou.com/courses/1145

##### 1. 数据来源

1. 雅虎财经
2. Python Quandl 模块

```
import quandl
# 该 API KEY 仅限实验楼课程使用，其他用途请自行注册
quandl.ApiConfig.api_key = 'DdXEs2xFciyUXrER9-a7'
quandl.get('WIKI/AAPL')
```

3. Pandas Datareader 模块

```
import pandas_datareader.data as web
import datetime
#start = datetime.datetime(2018, 1, 1)
end = datetime.datetime.now()
start = 10 * datatime.timedelta(days=365)
df = web.DataReader('000001.SZ', 'yahoo', start, end)

# DataReader可以设置缓存机制, 将数据缓存到本地, 推荐使用
import requests_cache
# 设定缓存及过期时间
expire_after = datetime.timedelta(days=3)
session = requests_cache.CachedSession(cache_name='cache', backend='sqlite', expire_after=expire_after)

end = datetime.datetime.now() # 指定结束时间
start = end - 10 * datetime.timedelta(days=365) # 10 年前

# 获取股票交易代码为 000001.SZ 的数据
df = web.DataReader('000001.SZ', 'yahoo', start, end, session=session)
df
```

##### 2. 数据预处理

1. ###### 缺失值处理

```
# 判断是否有缺失值
df.isnull().values.sum()
```

2. ###### 数据可视化

```
# pandas的dataframe自带一些画图的方法，也是基于matplotlib
df['Close'].plot(figsize=(16, 9))
```

通过 `plt.style.available` 查看全部绘图样式，推荐绘图样式：

- dark_background
- seaborn-whitegrid
- fivethirtyeight

```
plt.style.use('seaborn-whitegrid')

df.plot(figsize=(16, 9))
```

3. ###### 数据规范化

Min-Max 标准化是最常用的规范化手段之一，其公式为： 

$$\hat x=\frac{x-x_{min}}{x_{max}-x_{min}}$$

其中，$x_{max}$ 为样本数据的最大值，$x_{min}$ 为样本数据的最小值，$x_{max}-x_{min}$ 为极差。

未完待续





### 4.  Linear Regression with Python

#### 1. 数据预处理

- 数据清洗（查漏补空）
- 提取特征（这一步很关键，在生产中，往往会影响到最后的结果）
- 数据预估
- 等（其实数据预处理会占用大部分的工作，因为数据是你的模型的上限）

#### 2. 特征缩放（均值归一化）

有多种方式，常用的是标准归一

- [![{x_i} = \frac{{{x_i} - {\mu _i}}}{{{s_i}}}](https://camo.githubusercontent.com/5d8633c0d0efc2d6496b23144e77757b96c7605f/687474703a2f2f63686172742e617069732e676f6f676c652e636f6d2f63686172743f6368743d7478266368733d317830266368663d62672c732c4646464646463030266368636f3d3030303030302663686c3d253742785f6925374425323025334425323025354366726163253742253742253742785f692537442532302d2532302537422535436d752532305f69253744253744253744253742253742253742735f69253744253744253744)](https://camo.githubusercontent.com/5d8633c0d0efc2d6496b23144e77757b96c7605f/687474703a2f2f63686172742e617069732e676f6f676c652e636f6d2f63686172743f6368743d7478266368733d317830266368663d62672c732c4646464646463030266368636f3d3030303030302663686c3d253742785f6925374425323025334425323025354366726163253742253742253742785f692537442532302d2532302537422535436d752532305f69253744253744253744253742253742253742735f69253744253744253744)

```
# 特征缩放
def featureScaling(X):
    X_Scaler = np.array(X)
    # 得到X的列数
    n = X.shape[1]
    mu = np.zeros((1, n))  # 平均数
    sigma = np.zeros((1, n))  # 标准差
    mu = np.mean(X_Scaler, 0)  # 各列平均数
    sigma = np.std(X_Scaler, 0)  # 各列标准差
    for i in range(n):
        X_Scaler[:, i] = (X_Scaler[:, i] - mu[i]) / sigma[i]
    return X_Scaler, mu, sigma
```

#### 3. 数据预览（可视化预选模型）

通过数据预览，可以发现数据的基本分布，从而选出一个合适的模型，但是这一步可以跳过

#### 4. 补全参数

这一步就是为实现梯度下降做准备,我们会补全X的bias X0，初始化theta，alpha，迭代次数，X, y

#### 5. 实现梯度下降

先定义theta的temp和costFunction的历史J_history

```
def gradientDescent(X, y, theta, alpha, num_iters):
    m = len(y)
    n = len(theta)
    # 初始化theta并放到temp中
    # 这样写的好处会记录下theta的变化
    temp = np.matrix(np.zeros((n, num_iters)))
    J_history = np.zeros((num_iters, 1))

    for i in range(num_iters):
        h = np.dot(X, theta)
        temp[:, i] = theta - (alpha / m) * (np.dot(np.transpose(X), h - y))
        theta = temp[:, i]
        J_history[i] = computerCost(X, y, theta)
    return theta, J_history
```

#### 6. 可视化

画出迭代次数和J的变化图，看是否是凸函数

```
def plotJ(J_history, num_iters):
    X = np.arange(1, num_iters + 1)  # 创建一个间隔为1的等差数组
    plt.plot(X, J_history, color='blue')
    plt.xlabel('number of iterate')
    plt.ylabel(r'J(theta)')
    plt.title('change of cost J with iterator')
    plt.show()
```

#### 7. 进行测试（预测）

将预测的值和真实值进行比较，看是否需要优化。